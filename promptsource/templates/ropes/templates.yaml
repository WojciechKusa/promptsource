dataset: ropes
templates:
  0791ec30-6361-4e62-8dce-ca9cbf997acc: !Template
    answer_choices: null
    id: 0791ec30-6361-4e62-8dce-ca9cbf997acc
    jinja: "Please answer correctly the following question related to the paragraph\
      \ below. \n\n{{ question }}\n\n{{ situation }}\n\nHint: {{ background }}\n|||\n\
      {{ answers.text[0] if  answers.text[0] != None }}"
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: prompt_beginning
    reference: ''
  0909d72d-50c7-4cbb-bec4-1f891123717c: !Template
    answer_choices: null
    id: 0909d72d-50c7-4cbb-bec4-1f891123717c
    jinja: "{{ situation }}\n\nGiven the paragraph above, please answer correctly\
      \ the following question: \n\n{{ question }}\n|||\n{{ answers.text[0] if  answers.text[0]\
      \ != None }}"
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: false
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: prompt_bottom_no_hint
    reference: ''
  1e4944e7-4d5b-475c-8b04-4b523e96bc51: !Template
    answer_choices: null
    id: 1e4944e7-4d5b-475c-8b04-4b523e96bc51
    jinja: 'Background: {{ background }}


      Paragraph: {{ situation }}


      Given the paragraph above, please answer correctly the following question: {{
      question }}

      |||

      {{ answers.text[0] if  answers.text[0] != None }}'
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: prompt_bottom_hint_beginning
    reference: ''
  31faf808-80ff-47af-ac49-d2cd7a7abcaf: !Template
    answer_choices: null
    id: 31faf808-80ff-47af-ac49-d2cd7a7abcaf
    jinja: '{{ situation }}


      {{ question }}


      |||

      {{ answers.text[0] if  answers.text[0] != None }}'
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: false
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: plain_no_background
    reference: Task without background
  473f2c9c-9731-443c-a641-5e43770f7df6: !Template
    answer_choices: null
    id: 473f2c9c-9731-443c-a641-5e43770f7df6
    jinja: '{{ situation }}


      {{ question }}


      Hint: {{ background }}

      |||

      {{ answers.text[0] if  answers.text[0] != None }}'
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: true
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: plain_bottom_hint
    reference: ''
  a04f69ac-8122-4618-8426-185fc043feca: !Template
    answer_choices: null
    id: a04f69ac-8122-4618-8426-185fc043feca
    jinja: '{{ background }}


      {{ situation }}


      {{ question }}

      |||

      {{ answers.text[0] if  answers.text[0] != None }}'
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: plain
    reference: ''
  cc8f3c6b-b800-4b47-b6ec-e8febfdaad6f: !Template
    answer_choices: null
    id: cc8f3c6b-b800-4b47-b6ec-e8febfdaad6f
    jinja: "{{ situation }}\n\nGiven the paragraph above, please answer correctly\
      \ the following question: \n\n{{ question }}\n\nHint: {{ background }}\n|||\n\
      {{ answers.text[0] if  answers.text[0] != None }}"
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: true
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: prompt_mix
    reference: ''
  f62e0adb-ca74-4280-8ed3-8b53411d87ce: !Template
    answer_choices: null
    id: f62e0adb-ca74-4280-8ed3-8b53411d87ce
    jinja: 'I read this background article the other day: {{background}}


      I am facing a new situation today: {{situation}}


      Using the knowledge I acquired from the background article, how should I answer
      correctly the following question regarding my new situation: {{question}}|||

      {{ answers.text[0] if  answers.text[0] != None }}

      '
    metadata: !TemplateMetadata
      answer_span_indices: false
      counting: false
      long_distance: false
      negated_answers: false
      no_sep_2_sentences: false
      non_natural_language: false
      nontrivial_choices_given: true
      nontrivial_choices_hidden: false
      task_template: true
      trivial_choices_given: false
      trivial_choices_hidden: false
    name: funky_prompt
    reference: ''
